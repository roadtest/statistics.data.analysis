{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3030 Assignment 7 kNN Model Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22222222222222213, 0.6249999999999999, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.1666666666666668, 0.41666666666666663, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.11111111111111119, 0.5, 0.05084745762711865, 0.04166666666666667, 'Iris-setosa'], [0.08333333333333327, 0.4583333333333333, 0.0847457627118644, 0.04166666666666667, 'Iris-setosa'], [0.19444444444444448, 0.6666666666666666, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.30555555555555564, 0.7916666666666665, 0.11864406779661016, 0.12500000000000003, 'Iris-setosa'], [0.08333333333333327, 0.5833333333333333, 0.06779661016949151, 0.08333333333333333, 'Iris-setosa'], [0.19444444444444448, 0.5833333333333333, 0.0847457627118644, 0.04166666666666667, 'Iris-setosa'], [0.027777777777777922, 0.3749999999999999, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.1666666666666668, 0.4583333333333333, 0.0847457627118644, 0.0, 'Iris-setosa'], [0.30555555555555564, 0.7083333333333333, 0.0847457627118644, 0.04166666666666667, 'Iris-setosa'], [0.13888888888888887, 0.5833333333333333, 0.1016949152542373, 0.04166666666666667, 'Iris-setosa'], [0.13888888888888887, 0.41666666666666663, 0.06779661016949151, 0.0, 'Iris-setosa'], [0.0, 0.41666666666666663, 0.016949152542372895, 0.0, 'Iris-setosa'], [0.41666666666666663, 0.8333333333333333, 0.033898305084745756, 0.04166666666666667, 'Iris-setosa'], [0.38888888888888895, 1.0, 0.0847457627118644, 0.12500000000000003, 'Iris-setosa'], [0.30555555555555564, 0.7916666666666665, 0.05084745762711865, 0.12500000000000003, 'Iris-setosa'], [0.22222222222222213, 0.6249999999999999, 0.06779661016949151, 0.08333333333333333, 'Iris-setosa'], [0.38888888888888895, 0.7499999999999998, 0.11864406779661016, 0.08333333333333333, 'Iris-setosa'], [0.22222222222222213, 0.7499999999999998, 0.0847457627118644, 0.08333333333333333, 'Iris-setosa'], [0.30555555555555564, 0.5833333333333333, 0.11864406779661016, 0.04166666666666667, 'Iris-setosa'], [0.22222222222222213, 0.7083333333333333, 0.0847457627118644, 0.12500000000000003, 'Iris-setosa'], [0.08333333333333327, 0.6666666666666666, 0.0, 0.04166666666666667, 'Iris-setosa'], [0.22222222222222213, 0.5416666666666665, 0.11864406779661016, 0.16666666666666669, 'Iris-setosa'], [0.13888888888888887, 0.5833333333333333, 0.15254237288135591, 0.04166666666666667, 'Iris-setosa'], [0.19444444444444448, 0.41666666666666663, 0.1016949152542373, 0.04166666666666667, 'Iris-setosa'], [0.19444444444444448, 0.5833333333333333, 0.1016949152542373, 0.12500000000000003, 'Iris-setosa'], [0.25000000000000006, 0.6249999999999999, 0.0847457627118644, 0.04166666666666667, 'Iris-setosa'], [0.25000000000000006, 0.5833333333333333, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.11111111111111119, 0.5, 0.1016949152542373, 0.04166666666666667, 'Iris-setosa'], [0.13888888888888887, 0.4583333333333333, 0.1016949152542373, 0.04166666666666667, 'Iris-setosa'], [0.30555555555555564, 0.5833333333333333, 0.0847457627118644, 0.12500000000000003, 'Iris-setosa'], [0.25000000000000006, 0.8749999999999998, 0.0847457627118644, 0.0, 'Iris-setosa'], [0.3333333333333333, 0.9166666666666666, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.1666666666666668, 0.4583333333333333, 0.0847457627118644, 0.0, 'Iris-setosa'], [0.19444444444444448, 0.5, 0.033898305084745756, 0.04166666666666667, 'Iris-setosa'], [0.3333333333333333, 0.6249999999999999, 0.05084745762711865, 0.04166666666666667, 'Iris-setosa'], [0.1666666666666668, 0.4583333333333333, 0.0847457627118644, 0.0, 'Iris-setosa'], [0.027777777777777922, 0.41666666666666663, 0.05084745762711865, 0.04166666666666667, 'Iris-setosa'], [0.22222222222222213, 0.5833333333333333, 0.0847457627118644, 0.04166666666666667, 'Iris-setosa'], [0.19444444444444448, 0.6249999999999999, 0.05084745762711865, 0.08333333333333333, 'Iris-setosa'], [0.055555555555555594, 0.1249999999999999, 0.05084745762711865, 0.08333333333333333, 'Iris-setosa'], [0.027777777777777922, 0.5, 0.05084745762711865, 0.04166666666666667, 'Iris-setosa'], [0.19444444444444448, 0.6249999999999999, 0.1016949152542373, 0.20833333333333334, 'Iris-setosa'], [0.22222222222222213, 0.7499999999999998, 0.15254237288135591, 0.12500000000000003, 'Iris-setosa'], [0.13888888888888887, 0.41666666666666663, 0.06779661016949151, 0.08333333333333333, 'Iris-setosa'], [0.22222222222222213, 0.7499999999999998, 0.1016949152542373, 0.04166666666666667, 'Iris-setosa'], [0.08333333333333327, 0.5, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.27777777777777773, 0.7083333333333333, 0.0847457627118644, 0.04166666666666667, 'Iris-setosa'], [0.19444444444444448, 0.5416666666666665, 0.06779661016949151, 0.04166666666666667, 'Iris-setosa'], [0.7499999999999999, 0.5, 0.6271186440677966, 0.5416666666666666, 'Iris-versicolor'], [0.5833333333333334, 0.5, 0.5932203389830508, 0.5833333333333334, 'Iris-versicolor'], [0.7222222222222222, 0.4583333333333333, 0.6610169491525424, 0.5833333333333334, 'Iris-versicolor'], [0.3333333333333333, 0.1249999999999999, 0.5084745762711864, 0.5, 'Iris-versicolor'], [0.611111111111111, 0.3333333333333332, 0.6101694915254237, 0.5833333333333334, 'Iris-versicolor'], [0.38888888888888895, 0.3333333333333332, 0.5932203389830508, 0.5, 'Iris-versicolor'], [0.5555555555555555, 0.5416666666666665, 0.6271186440677966, 0.625, 'Iris-versicolor'], [0.1666666666666668, 0.1666666666666666, 0.38983050847457623, 0.375, 'Iris-versicolor'], [0.6388888888888887, 0.3749999999999999, 0.6101694915254237, 0.5, 'Iris-versicolor'], [0.25000000000000006, 0.2916666666666667, 0.4915254237288135, 0.5416666666666666, 'Iris-versicolor'], [0.19444444444444448, 0.0, 0.423728813559322, 0.375, 'Iris-versicolor'], [0.44444444444444453, 0.41666666666666663, 0.5423728813559322, 0.5833333333333334, 'Iris-versicolor'], [0.4722222222222222, 0.0833333333333334, 0.5084745762711864, 0.375, 'Iris-versicolor'], [0.4999999999999999, 0.3749999999999999, 0.6271186440677966, 0.5416666666666666, 'Iris-versicolor'], [0.361111111111111, 0.3749999999999999, 0.4406779661016949, 0.5, 'Iris-versicolor'], [0.6666666666666666, 0.4583333333333333, 0.576271186440678, 0.5416666666666666, 'Iris-versicolor'], [0.361111111111111, 0.41666666666666663, 0.5932203389830508, 0.5833333333333334, 'Iris-versicolor'], [0.41666666666666663, 0.2916666666666667, 0.5254237288135593, 0.375, 'Iris-versicolor'], [0.5277777777777778, 0.0833333333333334, 0.5932203389830508, 0.5833333333333334, 'Iris-versicolor'], [0.361111111111111, 0.20833333333333331, 0.4915254237288135, 0.4166666666666667, 'Iris-versicolor'], [0.44444444444444453, 0.5, 0.6440677966101694, 0.7083333333333334, 'Iris-versicolor'], [0.4999999999999999, 0.3333333333333332, 0.5084745762711864, 0.5, 'Iris-versicolor'], [0.5555555555555555, 0.20833333333333331, 0.6610169491525424, 0.5833333333333334, 'Iris-versicolor'], [0.4999999999999999, 0.3333333333333332, 0.6271186440677966, 0.4583333333333333, 'Iris-versicolor'], [0.5833333333333334, 0.3749999999999999, 0.559322033898305, 0.5, 'Iris-versicolor'], [0.6388888888888887, 0.41666666666666663, 0.576271186440678, 0.5416666666666666, 'Iris-versicolor'], [0.6944444444444443, 0.3333333333333332, 0.6440677966101694, 0.5416666666666666, 'Iris-versicolor'], [0.6666666666666666, 0.41666666666666663, 0.6779661016949152, 0.6666666666666666, 'Iris-versicolor'], [0.4722222222222222, 0.3749999999999999, 0.5932203389830508, 0.5833333333333334, 'Iris-versicolor'], [0.38888888888888895, 0.25, 0.423728813559322, 0.375, 'Iris-versicolor'], [0.3333333333333333, 0.1666666666666666, 0.47457627118644063, 0.4166666666666667, 'Iris-versicolor'], [0.3333333333333333, 0.1666666666666666, 0.4576271186440678, 0.375, 'Iris-versicolor'], [0.41666666666666663, 0.2916666666666667, 0.4915254237288135, 0.4583333333333333, 'Iris-versicolor'], [0.4722222222222222, 0.2916666666666667, 0.6949152542372881, 0.625, 'Iris-versicolor'], [0.30555555555555564, 0.41666666666666663, 0.5932203389830508, 0.5833333333333334, 'Iris-versicolor'], [0.4722222222222222, 0.5833333333333333, 0.5932203389830508, 0.625, 'Iris-versicolor'], [0.6666666666666666, 0.4583333333333333, 0.6271186440677966, 0.5833333333333334, 'Iris-versicolor'], [0.5555555555555555, 0.1249999999999999, 0.576271186440678, 0.5, 'Iris-versicolor'], [0.361111111111111, 0.41666666666666663, 0.5254237288135593, 0.5, 'Iris-versicolor'], [0.3333333333333333, 0.20833333333333331, 0.5084745762711864, 0.5, 'Iris-versicolor'], [0.3333333333333333, 0.25, 0.576271186440678, 0.4583333333333333, 'Iris-versicolor'], [0.4999999999999999, 0.41666666666666663, 0.6101694915254237, 0.5416666666666666, 'Iris-versicolor'], [0.41666666666666663, 0.25, 0.5084745762711864, 0.4583333333333333, 'Iris-versicolor'], [0.19444444444444448, 0.1249999999999999, 0.38983050847457623, 0.375, 'Iris-versicolor'], [0.361111111111111, 0.2916666666666667, 0.5423728813559322, 0.5, 'Iris-versicolor'], [0.38888888888888895, 0.41666666666666663, 0.5423728813559322, 0.4583333333333333, 'Iris-versicolor'], [0.38888888888888895, 0.3749999999999999, 0.5423728813559322, 0.5, 'Iris-versicolor'], [0.5277777777777778, 0.3749999999999999, 0.559322033898305, 0.5, 'Iris-versicolor'], [0.22222222222222213, 0.20833333333333331, 0.3389830508474576, 0.4166666666666667, 'Iris-versicolor'], [0.38888888888888895, 0.3333333333333332, 0.5254237288135593, 0.5, 'Iris-versicolor'], [0.5555555555555555, 0.5416666666666665, 0.847457627118644, 1.0, 'Iris-virginica'], [0.41666666666666663, 0.2916666666666667, 0.6949152542372881, 0.75, 'Iris-virginica'], [0.7777777777777776, 0.41666666666666663, 0.8305084745762712, 0.8333333333333334, 'Iris-virginica'], [0.5555555555555555, 0.3749999999999999, 0.7796610169491525, 0.7083333333333334, 'Iris-virginica'], [0.611111111111111, 0.41666666666666663, 0.8135593220338982, 0.8750000000000001, 'Iris-virginica'], [0.9166666666666665, 0.41666666666666663, 0.9491525423728813, 0.8333333333333334, 'Iris-virginica'], [0.1666666666666668, 0.20833333333333331, 0.5932203389830508, 0.6666666666666666, 'Iris-virginica'], [0.8333333333333333, 0.3749999999999999, 0.8983050847457626, 0.7083333333333334, 'Iris-virginica'], [0.6666666666666666, 0.20833333333333331, 0.8135593220338982, 0.7083333333333334, 'Iris-virginica'], [0.8055555555555556, 0.6666666666666666, 0.8644067796610169, 1.0, 'Iris-virginica'], [0.611111111111111, 0.5, 0.6949152542372881, 0.7916666666666666, 'Iris-virginica'], [0.5833333333333334, 0.2916666666666667, 0.7288135593220338, 0.75, 'Iris-virginica'], [0.6944444444444443, 0.41666666666666663, 0.7627118644067796, 0.8333333333333334, 'Iris-virginica'], [0.38888888888888895, 0.20833333333333331, 0.6779661016949152, 0.7916666666666666, 'Iris-virginica'], [0.41666666666666663, 0.3333333333333332, 0.6949152542372881, 0.9583333333333333, 'Iris-virginica'], [0.5833333333333334, 0.5, 0.7288135593220338, 0.9166666666666666, 'Iris-virginica'], [0.611111111111111, 0.41666666666666663, 0.7627118644067796, 0.7083333333333334, 'Iris-virginica'], [0.9444444444444444, 0.7499999999999998, 0.9661016949152542, 0.8750000000000001, 'Iris-virginica'], [0.9444444444444444, 0.25, 1.0, 0.9166666666666666, 'Iris-virginica'], [0.4722222222222222, 0.0833333333333334, 0.6779661016949152, 0.5833333333333334, 'Iris-virginica'], [0.7222222222222222, 0.5, 0.7966101694915254, 0.9166666666666666, 'Iris-virginica'], [0.361111111111111, 0.3333333333333332, 0.6610169491525424, 0.7916666666666666, 'Iris-virginica'], [0.9444444444444444, 0.3333333333333332, 0.9661016949152542, 0.7916666666666666, 'Iris-virginica'], [0.5555555555555555, 0.2916666666666667, 0.6610169491525424, 0.7083333333333334, 'Iris-virginica'], [0.6666666666666666, 0.5416666666666665, 0.7966101694915254, 0.8333333333333334, 'Iris-virginica'], [0.8055555555555556, 0.5, 0.847457627118644, 0.7083333333333334, 'Iris-virginica'], [0.5277777777777778, 0.3333333333333332, 0.6440677966101694, 0.7083333333333334, 'Iris-virginica'], [0.4999999999999999, 0.41666666666666663, 0.6610169491525424, 0.7083333333333334, 'Iris-virginica'], [0.5833333333333334, 0.3333333333333332, 0.7796610169491525, 0.8333333333333334, 'Iris-virginica'], [0.8055555555555556, 0.41666666666666663, 0.8135593220338982, 0.625, 'Iris-virginica'], [0.8611111111111112, 0.3333333333333332, 0.8644067796610169, 0.75, 'Iris-virginica'], [1.0, 0.7499999999999998, 0.9152542372881356, 0.7916666666666666, 'Iris-virginica'], [0.5833333333333334, 0.3333333333333332, 0.7796610169491525, 0.8750000000000001, 'Iris-virginica'], [0.5555555555555555, 0.3333333333333332, 0.6949152542372881, 0.5833333333333334, 'Iris-virginica'], [0.4999999999999999, 0.25, 0.7796610169491525, 0.5416666666666666, 'Iris-virginica'], [0.9444444444444444, 0.41666666666666663, 0.8644067796610169, 0.9166666666666666, 'Iris-virginica'], [0.5555555555555555, 0.5833333333333333, 0.7796610169491525, 0.9583333333333333, 'Iris-virginica'], [0.5833333333333334, 0.4583333333333333, 0.7627118644067796, 0.7083333333333334, 'Iris-virginica'], [0.4722222222222222, 0.41666666666666663, 0.6440677966101694, 0.7083333333333334, 'Iris-virginica'], [0.7222222222222222, 0.4583333333333333, 0.7457627118644068, 0.8333333333333334, 'Iris-virginica'], [0.6666666666666666, 0.4583333333333333, 0.7796610169491525, 0.9583333333333333, 'Iris-virginica'], [0.7222222222222222, 0.4583333333333333, 0.6949152542372881, 0.9166666666666666, 'Iris-virginica'], [0.41666666666666663, 0.2916666666666667, 0.6949152542372881, 0.75, 'Iris-virginica'], [0.6944444444444443, 0.5, 0.8305084745762712, 0.9166666666666666, 'Iris-virginica'], [0.6666666666666666, 0.5416666666666665, 0.7966101694915254, 1.0, 'Iris-virginica'], [0.6666666666666666, 0.41666666666666663, 0.711864406779661, 0.9166666666666666, 'Iris-virginica'], [0.5555555555555555, 0.20833333333333331, 0.6779661016949152, 0.75, 'Iris-virginica'], [0.611111111111111, 0.41666666666666663, 0.711864406779661, 0.7916666666666666, 'Iris-virginica'], [0.5277777777777778, 0.5833333333333333, 0.7457627118644068, 0.9166666666666666, 'Iris-virginica'], [0.44444444444444453, 0.41666666666666663, 0.6949152542372881, 0.7083333333333334, 'Iris-virginica']]\n",
      "Train set: 102\n",
      "Test set: 48\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-versicolor', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "Accuracy: 97.91666666666666%\n"
     ]
    }
   ],
   "source": [
    "# Example of kNN implemented from Scratch in Python\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        \n",
    "        # Convert observations to float and capture max and min value of each predictor\n",
    "        # Initialize minval and maxval to first observation\n",
    "        minval = []\n",
    "        maxval = []\n",
    "        for y in range(4):\n",
    "            minval.append(float(dataset[0][y]))\n",
    "            maxval.append(float(dataset[0][y]))\n",
    "               \n",
    "        for x in range(len(dataset)): # note there appears to be a bug in original code that would drop the last obseration\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "                minval[y] = min(minval[y], dataset[x][y])\n",
    "                maxval[y] = max(maxval[y], dataset[x][y])\n",
    "        \n",
    "        # Normalize all predictors to between 0 and 1\n",
    "        # Alternatively, if we have reason to believe the data is Normally distributed we could normalize to units of Z\n",
    "        # by finding the mean and std. dev. of each predictor, then adjusting each of the predictor observations by subtracting\n",
    "        # the mean and dividing by the s.d. (Z = (x - mu) / sigma)\n",
    "        # Here though we're subtracting the min value and dividing by the range\n",
    "        for x in range(len(dataset)):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = (dataset[x][y] - minval[y]) / (maxval[y] - minval[y])\n",
    "        print dataset\n",
    "        \n",
    "        # Split dataset into training and test\n",
    "        for x in range(len(dataset)):\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "\n",
    "\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "# Add a function for Manhattan distance\n",
    "def manhattanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += abs(instanc1[x] - instance2[x])\n",
    "    return distance\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        # to use Manhattan distance substitute above with\n",
    "        # dist = manhattanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "# To use for numeric prediction:\n",
    "# We need the response (i.e. the target) to be a value rather than a class label, but assuming that it is, alter the above\n",
    "# as follows and use this function instead\n",
    "# Rather than return the label with the most votes, this returns the average of the k nearest neighbors.\n",
    "def getPrediction(neighbors):\n",
    "    est = 0.0\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        est += response\n",
    "    return est/len(neighbors)\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    # prepare data\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    split = 0.67\n",
    "    loadDataset('iris.dat', split, trainingSet, testSet)\n",
    "    print 'Train set: ' + repr(len(trainingSet))\n",
    "    print 'Test set: ' + repr(len(testSet))\n",
    "    # generate predictions\n",
    "    predictions=[]\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + repr(accuracy) + '%')\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
